# ğŸ–ï¸ PalmPilot: Gesture Control with OpenVINO

PalmPilot is a high-performance, real-time hand gesture control system for your desktop. Built with Python and powered by Intel's OpenVINO toolkit, it offers a fast and intuitive way to interact with your applications without a mouse or keyboard.

---

## âœ¨ Features

-   **High-Performance Inference**: Leverages the OpenVINOâ„¢ toolkit for optimized, low-latency gesture recognition on Intel hardware.
-   **Modern GUI**: A clean and user-friendly dashboard built with PyQt6 to manage the engine, select modes, and view gesture mappings.
-   **Customizable Application Modes**: Pre-configured modes for presentations, media players, and general desktop use. Easily create and edit your own modes.
-   **Direct System Control**: Seamlessly controls the mouse cursor, performs clicks, scrolls, and executes keyboard shortcuts based on your hand movements.
-   **Robust Hand Tracking**: Utilizes a multi-stage pipeline for accurate hand detection and 21-point landmark tracking.

---

## ğŸ› ï¸ Technology Stack

-   **Core Engine**: Python
-   **Inference**: OpenVINOâ„¢
-   **GUI**: PyQt6
-   **CV & Image Processing**: OpenCV, NumPy
-   **System Automation**: PyAutoGUI

---

## ğŸ§  Model Pipeline

PalmPilot uses a chain of OpenVINO IR models (`.xml` and `.bin`) to process the video feed and recognize gestures.

| Model                     | Description                                          |
| ------------------------- | ---------------------------------------------------- |
| `hand_detector`           | Detects the presence and bounding box of a hand.     |
| `hand_landmarks_detector` | Locates 21 key hand landmarks within the box.        |
| `gesture_embedder`        | Encodes landmark vectors into a feature representation.|
| `canned_gesture_classifier`| Classifies the feature vector into a specific gesture. |

---

## âš™ï¸ Setup and Installation

### 1. Clone the Repository

```bash
git clone https://github.com/vijaykr338/gesture-control.git
cd gesture-control
```

### 2. Create a Virtual Environment

Using a virtual environment is strongly recommended to keep dependencies isolated.

```bash
# Create the environment
python -m venv venv

# Activate the environment
# On Windows:
venv\Scripts\activate
# On macOS/Linux:
source venv/bin/activate
```

### 3. Install Dependencies

The project's dependencies are listed in `requirement.txt`. Install them using pip.

```bash
pip install -r requirement.txt
```
*(Note: The requirements file contains all packages, including development tools like Jupyter.)*

---

## ğŸš€ How to Run

Once the setup is complete, launch the main application:

```bash
python gui_main.py
```

From the GUI, you can:
-   **Start/Stop** the gesture detection engine.
-   **Select** the active application mode from the dropdown.
-   **View** the gestures and their assigned actions for the current mode.
-   **Create or Edit** custom modes to fit your workflow.

---

## ğŸ“ Project Structure

```
.
â”œâ”€â”€ mediapipeModels/            # OpenVINO IR models (.xml, .bin)
â”œâ”€â”€ application_modes.py        # Handles loading and managing control modes.
â”œâ”€â”€ config_manager.py           # Manages gesture configurations from JSON.
â”œâ”€â”€ detection_models.py         # Loads and manages the OpenVINO models.
â”œâ”€â”€ event_system.py             # A simple event bus for component communication.
â”œâ”€â”€ gesture_config.json         # Main JSON configuration for gestures and modes.
â”œâ”€â”€ gesture_engine.py           # Core logic for the gesture recognition pipeline.
â”œâ”€â”€ gesture_processor.py        # Translates gestures into system actions (e.g., mouse clicks).
â”œâ”€â”€ gui_main.py                 # The main entry point for the PyQt6 GUI.
â”œâ”€â”€ gui_worker.py               # QThread worker to run the engine without freezing the GUI.
â”œâ”€â”€ hand_landmark.py            # Constants for hand landmark points.
â”œâ”€â”€ requirement.txt             # Python dependencies.
â””â”€â”€ README.md                   # This file.
```

---

## ğŸ“„ License

This project is licensed under the MIT License. See the `LICENSE` file for details.
*(You should add a LICENSE file to your repository)*